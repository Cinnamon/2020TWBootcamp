{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ast\n",
    "import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer, BertForQuestionAnswering\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class SashimiDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(SashimiDataset, self).__init__()\n",
    "        self.text = data.Text\n",
    "        self.label = data.Label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.text.shape[0]*4\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text[idx // len(QUESTIONS)]\n",
    "        qs_idx = idx % len(QUESTIONS)\n",
    "        label = self.label[idx // len(QUESTIONS)][qs_idx]\n",
    "        question = QUESTIONS[qs_idx]\n",
    "        \n",
    "        inputs = tokenizer(question, text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "        label = torch.LongTensor(label)\n",
    "        \n",
    "        plus_idx = (inputs['input_ids'] == 102).nonzero()[0,1]\n",
    "        label += plus_idx + 1\n",
    "        \n",
    "        return inputs, label\n",
    "    \n",
    "    \n",
    "config = AutoConfig.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
    "model = BertForQuestionAnswering.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\", use_fast=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sup! Sup. Let's see a play on Friday? Ok. Wher...</td>\n",
       "      <td>[[10, 12], [13, 14], [51, 52], [31, 33]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey. Would you want to go somewhere on Wednesd...</td>\n",
       "      <td>[[7, 8], [9, 10], [50, 51], [28, 29]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yo, what's up? Nothing much. Let's go to a par...</td>\n",
       "      <td>[[14, 17], [18, 19], [61, 62], [38, 40]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yo, what's up? Nothing much. Would you want to...</td>\n",
       "      <td>[[15, 16], [17, 18], [59, 60], [33, 35]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hey, how are you doing? I’m good, and you? I’m...</td>\n",
       "      <td>[[26, 28], [29, 30], [70, 71], [49, 51]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Sup! Sup. Let's see a play on Friday? Ok. Wher...   \n",
       "1  Hey. Would you want to go somewhere on Wednesd...   \n",
       "2  Yo, what's up? Nothing much. Let's go to a par...   \n",
       "3  Yo, what's up? Nothing much. Would you want to...   \n",
       "4  Hey, how are you doing? I’m good, and you? I’m...   \n",
       "\n",
       "                                      Label  \n",
       "0  [[10, 12], [13, 14], [51, 52], [31, 33]]  \n",
       "1     [[7, 8], [9, 10], [50, 51], [28, 29]]  \n",
       "2  [[14, 17], [18, 19], [61, 62], [38, 40]]  \n",
       "3  [[15, 16], [17, 18], [59, 60], [33, 35]]  \n",
       "4  [[26, 28], [29, 30], [70, 71], [49, 51]]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUESTIONS = [\n",
    "    'What activity?',\n",
    "    'What date?',\n",
    "    'What time?',\n",
    "    'Where to go?'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('./data/training_data.csv', sep='\\t')\n",
    "data['Text'] = [ast.literal_eval(data.Text[i])[0] for i in range(data.shape[0])]\n",
    "data['Label'] = [ast.literal_eval(data.Label[i]) for i in range(data.shape[0])]\n",
    "    \n",
    "dataset = SashimiDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=4)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfccd74c6bb48b7995ed11be4b126c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss 0.008059692569077015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c14823bb9424b41845a4e4ac36fc1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss 0.1382034569978714\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562bbf164a5048acb85bd8a146265f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss 0.004682702012360096\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 2e-5)\n",
    "\n",
    "for epoch in range(3):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for inputs, label in tqdm.notebook.tqdm(dataloader):\n",
    "        # Reform the inputs\n",
    "        for k in inputs.keys():\n",
    "            inputs[k] = inputs[k].squeeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        predict = torch.stack(outputs, -1)\n",
    "\n",
    "        loss = loss_fn(predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        break\n",
    "        \n",
    "    print(f'Train loss {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0105, grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(torch.stack([start, end], -1), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([start, start], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What activity?\t0\t18\t[CLS] What activity? [SEP] Sup! Sup. Would you want to go to a party\n",
      "What date?\t0\t0\t[CLS]\n",
      "What time?\t58\t59\t7 am\n",
      "Where to go?\t0\t0\t[CLS]\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"Sup! Sup. Let's see a play on Friday? Ok. Where should we meet? I don't know. How about the theme park? Sure! When? 9 pm? Sorry, I can't. How about 11 pm? Sure. See you then!\"\n",
    "\n",
    "for qs in QUESTIONS:\n",
    "    inputs = tokenizer(qs, data.Text[1000], max_length=128, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        start, end = torch.argmax(outputs[0]), torch.argmax(outputs[1])\n",
    "        print(f\"{qs}\\t{start}\\t{end}\\t{tokenizer.decode(inputs['input_ids'][0,start:end+1].tolist())}\\t{tokenizer.decode(inputs['input_ids'][0,start:end+1].tolist())}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54663d8d9e543eeb5bbd6b4fafda7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:    [[15, 17], [18, 19], [56, 57], [37, 39]]\n",
      "Predict: [[15, 17], [18, 19], [56, 57], [37, 39]]\n",
      "\n",
      "True:    [[12, 13], [14, 15], [55, 56], [34, 35]]\n",
      "Predict: [[0, 34], [14, 14], [54, 43], [33, 35]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, (inputs, label) in tqdm.notebook.tqdm(enumerate(dataloader)):\n",
    "    for k in inputs.keys():\n",
    "        inputs[k] = inputs[k].squeeze(1)\n",
    "    outputs = model(**inputs)\n",
    "    start, end = torch.argmax(outputs[0], -1), torch.argmax(outputs[1], -1)\n",
    "    print(f\"True:    {label.tolist()}\\nPredict: {torch.stack((start, end)).T.tolist()}\\n\")\n",
    "    if idx == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sup! Sup. Let's see a play on Friday? Ok. Wher...</td>\n",
       "      <td>[[10, 12], [13, 14], [51, 52], [31, 33]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey. Would you want to go somewhere on Wednesd...</td>\n",
       "      <td>[[7, 8], [9, 10], [50, 51], [28, 29]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yo, what's up? Nothing much. Let's go to a par...</td>\n",
       "      <td>[[14, 17], [18, 19], [61, 62], [38, 40]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yo, what's up? Nothing much. Would you want to...</td>\n",
       "      <td>[[15, 16], [17, 18], [59, 60], [33, 35]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hey, how are you doing? I’m good, and you? I’m...</td>\n",
       "      <td>[[26, 28], [29, 30], [70, 71], [49, 51]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Hey. Would you want to ice skating on Wednesda...</td>\n",
       "      <td>[[7, 8], [9, 10], [48, 49], [27, 28]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Heyo! Do you want to catch up on Friday? Sound...</td>\n",
       "      <td>[[8, 9], [10, 11], [52, 53], [26, 27]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Yo, what's up? Nothing much. Do you want to gr...</td>\n",
       "      <td>[[15, 16], [17, 18], [62, 63], [36, 37]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Yo, what's up? Nothing much. Let's go to a par...</td>\n",
       "      <td>[[14, 17], [18, 18], [60, 62], [35, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Sup! Sup. Would you want to see a movie today?...</td>\n",
       "      <td>[[11, 13], [14, 14], [51, 52], [31, 33]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0     Sup! Sup. Let's see a play on Friday? Ok. Wher...   \n",
       "1     Hey. Would you want to go somewhere on Wednesd...   \n",
       "2     Yo, what's up? Nothing much. Let's go to a par...   \n",
       "3     Yo, what's up? Nothing much. Would you want to...   \n",
       "4     Hey, how are you doing? I’m good, and you? I’m...   \n",
       "...                                                 ...   \n",
       "1995  Hey. Would you want to ice skating on Wednesda...   \n",
       "1996  Heyo! Do you want to catch up on Friday? Sound...   \n",
       "1997  Yo, what's up? Nothing much. Do you want to gr...   \n",
       "1998  Yo, what's up? Nothing much. Let's go to a par...   \n",
       "1999  Sup! Sup. Would you want to see a movie today?...   \n",
       "\n",
       "                                         Label  \n",
       "0     [[10, 12], [13, 14], [51, 52], [31, 33]]  \n",
       "1        [[7, 8], [9, 10], [50, 51], [28, 29]]  \n",
       "2     [[14, 17], [18, 19], [61, 62], [38, 40]]  \n",
       "3     [[15, 16], [17, 18], [59, 60], [33, 35]]  \n",
       "4     [[26, 28], [29, 30], [70, 71], [49, 51]]  \n",
       "...                                        ...  \n",
       "1995     [[7, 8], [9, 10], [48, 49], [27, 28]]  \n",
       "1996    [[8, 9], [10, 11], [52, 53], [26, 27]]  \n",
       "1997  [[15, 16], [17, 18], [62, 63], [36, 37]]  \n",
       "1998  [[14, 17], [18, 18], [60, 62], [35, 36]]  \n",
       "1999  [[11, 13], [14, 14], [51, 52], [31, 33]]  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/8000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 12])\n",
      "tensor(4) tensor([15, 17])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/8000 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ast\n",
    "import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer, BertForQuestionAnswering\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class SashimiDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(SashimiDataset, self).__init__()\n",
    "        self.text = data.Text\n",
    "        self.label = data.Label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.text.shape[0]*4\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text[idx // len(QUESTIONS)]\n",
    "        qs_idx = idx % len(QUESTIONS)\n",
    "        label = self.label[idx // len(QUESTIONS)][qs_idx]\n",
    "        question = QUESTIONS[qs_idx]\n",
    "        \n",
    "        inputs = tokenizer(question, text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "        label = torch.LongTensor(label)\n",
    "        \n",
    "        print(label)\n",
    "        \n",
    "        plus_idx = (inputs['input_ids'] == 102).nonzero()[0,1]\n",
    "        label += plus_idx + 1\n",
    "        \n",
    "        print(plus_idx, label)\n",
    "        \n",
    "        return inputs, label\n",
    "        \n",
    "        \n",
    "def get_data(path, sep=',', index_col=None):\n",
    "    data = pd.read_csv(path, sep=sep, index_col=index_col)\n",
    "    data['Text'] = [ast.literal_eval(data.Text[i])[0] for i in range(data.shape[0])]\n",
    "    data['Label'] = [ast.literal_eval(data.Label[i]) for i in range(data.shape[0])]\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
    "    model = BertForQuestionAnswering.from_pretrained(\"deepset/bert-base-cased-squad2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"deepset/bert-base-cased-squad2\", use_fast=True)\n",
    "    \n",
    "    QUESTIONS = [\n",
    "        'What activity?',\n",
    "        'What date?',\n",
    "        'What time?',\n",
    "        'Where to go?'\n",
    "    ]\n",
    "\n",
    "    data = get_data('./data/training_data.csv', sep='\\t')\n",
    "    dataset = SashimiDataset(data)\n",
    "    dataloader = DataLoader(dataset, batch_size=1)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), 2e-5)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(3):\n",
    "        total_loss = 0\n",
    "        \n",
    "        for inputs, label in tqdm.tqdm(dataloader):\n",
    "            # Reform the inputs\n",
    "            for k in inputs.keys():\n",
    "                inputs[k] = inputs[k].squeeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            start, end = outputs[0], outputs[1]\n",
    "            label = label\n",
    "\n",
    "            loss = loss_fn(start, label[:,0]) + loss_fn(end, label[:,1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            break\n",
    "            \n",
    "        break\n",
    "            \n",
    "        print(f'Train loss {total_loss}')\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\t18\ta play on Friday\n"
     ]
    }
   ],
   "source": [
    "start, end = torch.argmax(outputs[0]), torch.argmax(outputs[1])\n",
    "print(f\"{start}\\t{end}\\t{tokenizer.decode(inputs['input_ids'][0,start:end+1].tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sup! Sup. Would you want to go to a party tomorrow? Sure. Where should we meet? I don't know. How about the Japanese place? Great. When? You free 4 am? Sorry, I can't. How about 7 am? Ok. See you then!\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'][1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
